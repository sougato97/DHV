<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- saved from url=(0037)https://yifanjiang.net/MalleConv.html -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>DHV</title>
<link rel="stylesheet" href="./DHV_files/bootstrap.min.css">
<link rel="stylesheet" href="./DHV_files/temp.css">
<link rel="stylesheet" href="./DHV_files/DHV_style.css">
<link href="https://www.google.com/favicon.ico" rel="icon">
</head>
<body data-gr-c-s-loaded="true" data-new-gr-c-s-check-loaded="14.1025.0" data-gr-ext-installed="">
<div class="container">
<table border="0" align="center">
<tbody><tr>
<td width="1500" height="200" align="center" valign="middle">
<span class="title"><h1>On Deep Learning for Dorsal Hand Vein <br> Recognition</h1></span></td>
</tr>
<tr>
<td colspan="3" align="center"><h5>
<a href="https://sougato97.github.io/" target="_blank">Sougato Bagchi<sup>1,*</sup></a>,
<a href="https://www.linkedin.com/in/geetartho-chanda/" target="_blank">Geetartho Chanda<sup>1,*</sup></a>,
<a href="https://scholar.google.co.in/citations?user=LrW6Hb4AAAAJ&hl=en" target="_blank">Akshay Agarwal<sup>2</sup></a>,
<a href="https://www.buffalo.edu/cubs/members.host.html/content/shared/engineering/computer-science-engineering/profiles/faculty/ladder/ratha-nalini.html" target="_blank">Nalini Ratha<sup>1</sup></a>,
<br>

</h5></td>
</tr>
<tr>
<td colspan="3" align="center"><h4> <sup>1</sup> University at Buffalo, &nbsp; <sup>2</sup> IISER Bhopal, India </h4> </td>
</tr>
<!-- <tr>
<td colspan="3" align="center"><h5> <a href="https://arxiv.org/pdf/2201.00392.pdf" target="_blank">[Paper]</a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a href="https://yifanjiang.net/MalleConv_files/MalleConv.zip" target="_blank">[Code]</a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a href="https://yifanjiang.net/MalleConv_files/supplementary.pdf" target="_blank">[Supplementary Materials]</a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </h5></td>
</tr> -->
<tr>
    <!-- <td colspan="3" align="center"><h5> <a href="https://arxiv.org/pdf/2201.00392.pdf" target="_blank">[Paper]</a>  -->
        <!-- &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a href="https://yifanjiang.net/MalleConv_files/MalleConv.zip" target="_blank">[Code]</a>  -->
        <!-- &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a href="https://yifanjiang.net/MalleConv_files/supplementary.pdf" target="_blank">[Supplementary Materials]</a>  -->
        <!-- &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </h5></td> -->
</tr>
</tbody></table>
<br>
<p><img src="./DHV_files/pictures.png" style="margin:auto;max-width:100%" align="middle"></p>
<div class="text" style="text-align: left;">
<h2>Abstract</h2>
<p>Many image processing networks apply a single set of static convolutional kernels across the entire input image, which is sub-optimal for natural images, as they often consist of heterogeneous visual patterns. Recent works in classification, segmentation, and image restoration have demonstrated that dynamic kernels outperform static kernels at modeling local image statistics. However, these works often adopt per-pixel convolution kernels, which introduce high memory and computation costs. To achieve spatial-varying processing without significant overhead, we present Malleable Convolution (MalleConv), as an efficient variant of dynamic convolution. The weights of MalleConv are dynamically produced by an efficient predictor network capable of generating content-dependent outputs at specific spatial locations. Unlike previous works, MalleConv generates a much smaller set of spatially-varying kernels from input, which enlarges the network's receptive field and significantly reduces computational and memory costs. These kernels are then applied to a full-resolution feature map through an efficient slice-and-conv operator with minimum memory overhead. We further build an efficient denoising network using MalleConv, coined as MalleNet. It achieves high quality results without very deep architecture, e.g., reaching 8.91x faster speed compared to the best performed denoising algorithms (SwinIR), while maintaining similar performance. We also show that a single MalleConv added to a standard convolution-based backbone can contribute significantly to reducing the computational cost or boosting image quality at a similar cost</p>
</div>
</div>
<br>



<p></p><br>
<grammarly-desktop-integration data-grammarly-shadow-root="true"></grammarly-desktop-integration>
<div id="speechify-global-notifications"></div><div id="speechify-summarization-fullscreen-mode" style="position: fixed; inset: 0px; overflow: auto; background: white; z-index: 1999; display: none;"></div><div id="speechify-screenshot-mode" style="position: fixed; top: 0px; right: 0px; width: 100%; min-height: 100%; z-index: 9999; display: none;"></div></body></html>